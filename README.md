# Ses TanÄ±ma ile Ortamdaki KiÅŸi SayÄ±sÄ±nÄ± Tespit Eden GÃ¶mÃ¼lÃ¼ Sistem
*(Not: Bu yazÄ± yapay zeka ile oluÅŸturulmuÅŸtur.)*

Bu proje, bir kapalÄ± ortamdaki ses sinyallerini analiz ederek, konuÅŸan kiÅŸi sayÄ±sÄ±nÄ± gerÃ§ek zamanlÄ± olarak tespit eden bir gÃ¶mÃ¼lÃ¼ sistem prototipidir. Proje, kamera kullanÄ±mÄ±nÄ±n mahremiyet veya yetersiz Ä±ÅŸÄ±k nedeniyle uygun olmadÄ±ÄŸÄ± durumlar iÃ§in enerji verimliliÄŸi ve otomasyon Ã§Ã¶zÃ¼mleri sunmayÄ± amaÃ§lamaktadÄ±r.

Bu Ã§alÄ±ÅŸma, **TÃœBÄ°TAK 2209-A - Ãœniversite Ã–ÄŸrencileri AraÅŸtÄ±rma Projeleri DesteÄŸi ProgramÄ±** kapsamÄ±nda desteklenmiÅŸtir.

---

[English Version Below](#english-version)

---

## TÃ¼rkÃ§e AÃ§Ä±klama

### ğŸ¯ Projenin AmacÄ±

Projenin temel amacÄ±, bir mekandaki konuÅŸmacÄ± sayÄ±sÄ±nÄ± ses analizi yoluyla tespit etmektir. Tespit edilen bu bilgi, akÄ±llÄ± binalardaki aydÄ±nlatma, Ä±sÄ±tma ve iklimlendirme sistemlerini otomatik olarak kontrol ederek enerji tasarrufu saÄŸlamak gibi Ã§eÅŸitli otomasyon senaryolarÄ±nda kullanÄ±labilir. Sistem, mahremiyeti Ã¶n planda tutan, kamera tabanlÄ± sistemlere etkili bir alternatif olarak tasarlanmÄ±ÅŸtÄ±r.

### ğŸ–¼ï¸ GÃ¶rseller

**Devre ÅemasÄ±:**
[![Image](https://i.hizliresim.com/dciq0h9.png)](https://hizliresim.com/dciq0h9)

### ğŸ› ï¸ Teknoloji Mimarisi

#### DonanÄ±m
* **Ä°ÅŸlemci:** Raspberry Pi 5 (8GB)
* **Mikrofon:** MAX9814 Mikrofon AmplifikatÃ¶rÃ¼ (Otomatik KazanÃ§ KontrollÃ¼)
* **ADC:** MCP3204 12-bit Analog-Dijital Ã‡evirici
* **Ekran:** Raspberry Pi 5 inÃ§ Dokunmatik Ekran (GeliÅŸtirme ve Ã§Ä±ktÄ± gÃ¶rselleÅŸtirme iÃ§in)
* **DiÄŸer:** Resmi Raspberry Pi 27W GÃ¼Ã§ AdaptÃ¶rÃ¼, Breadboard, Jumper Kablolar

#### YazÄ±lÄ±m
* **Dil:** Python 3
* **Ana KÃ¼tÃ¼phaneler:**
  * `pyannote.audio`: KonuÅŸmacÄ± tespiti (diarization) iÃ§in. `pyannote/speaker-diarization-3.1` modeli kullanÄ±lmÄ±ÅŸtÄ±r.
  * `spidev`: Raspberry Pi ve MCP3204 ADC arasÄ±nda SPI haberleÅŸmesi iÃ§in.
  * `librosa` & `soundfile`: Ses dosyalarÄ±nÄ± okuma ve iÅŸleme iÃ§in.
  * `noisereduce`: GÃ¼rÃ¼ltÃ¼ azaltma iÃ§in.
  * `webrtcvad`: Ses aktivite tespiti (VAD) iÃ§in.
  * `numpy`: SayÄ±sal iÅŸlemler iÃ§in.
  * `matplotlib`: Ã‡Ä±ktÄ± grafiklerini oluÅŸturmak iÃ§in.

### âš™ï¸ Sistem Mimarisi

Sistem, 4 ana modÃ¼lden oluÅŸan bir iÅŸ akÄ±ÅŸÄ±na sahiptir:
1.  **Ses Yakalama (`capture.py`):** MAX9814 ve MCP3204 aracÄ±lÄ±ÄŸÄ±yla analog ses sinyalini yakalar ve dijitalleÅŸtirir.
2.  **Ses Ã–niÅŸleme (`onisleme.py`):** Yakalanan sesten gÃ¼rÃ¼ltÃ¼yÃ¼ azaltÄ±r, sinyali normalleÅŸtirir ve sessiz kÄ±sÄ±mlarÄ± atar.
3.  **Analiz (`analiz.py`):** `pyannote.audio` modelini kullanarak temizlenmiÅŸ ses segmentindeki konuÅŸmacÄ±larÄ± tespit eder ve etiketler.
4.  **Ã‡Ä±ktÄ± (`output.py`):** Analiz sonuÃ§larÄ±nÄ± terminalde gÃ¶sterir ve konuÅŸmacÄ± zaman Ã§izelgesi grafiÄŸi oluÅŸturur.

### ğŸš€ Kurulum

1.  **DonanÄ±m Kurulumu:** YukarÄ±daki devre ÅŸemasÄ±nÄ± referans alarak bileÅŸenleri bir breadboard Ã¼zerinde birleÅŸtirin.
2.  **Raspberry Pi YapÄ±landÄ±rmasÄ±:**
    * Raspberry Pi OS (64-bit) iÅŸletim sistemini kurun.
    * Terminali aÃ§Ä±n ve `sudo raspi-config` komutunu Ã§alÄ±ÅŸtÄ±rÄ±n.
    * `Interface Options` -> `SPI` menÃ¼sÃ¼ne gidin ve SPI arayÃ¼zÃ¼nÃ¼ etkinleÅŸtirin.
3.  **YazÄ±lÄ±m BaÄŸÄ±mlÄ±lÄ±klarÄ±:**
    * Proje dosyalarÄ±nÄ± klonlayÄ±n: `git clone [Projenizin GitHub linkini buraya ekleyin]`
    * Proje dizinine gidin: `cd [proje-klasor-adi]`
    * Gerekli Python kÃ¼tÃ¼phanelerini kurun:
      ```bash
      pip install -r requirements.txt
      ```

### ğŸ”§ YapÄ±landÄ±rma

Bu projenin Ã§alÄ±ÅŸmasÄ± iÃ§in bir Hugging Face kullanÄ±cÄ± belirtecine (token) ihtiyacÄ±nÄ±z vardÄ±r.

1.  [Hugging Face](https://huggingface.co/settings/tokens) sitesinden bir `READ` yetkisine sahip token oluÅŸturun.
2.  OluÅŸturduÄŸunuz token'Ä± `config.py` dosyasÄ±ndaki `HUGGINGFACE_TOKEN` deÄŸiÅŸkenine atayÄ±n:
    ```python
    # config.py
    HUGGINGFACE_TOKEN = "hf_SizinHuggingFaceTokeninizBurayaGelecek"
    ```

### âš¡ KullanÄ±m

Proje `main.py` betiÄŸi Ã¼zerinden Ã§alÄ±ÅŸtÄ±rÄ±lÄ±r. Ä°ki ana modu vardÄ±r:

1.  **CanlÄ± Ses Ä°ÅŸleme:** Mikrofondan anlÄ±k olarak ses kaydÄ± alÄ±r ve iÅŸler.
    ```bash
    python3 main.py --live
    ```
    * Belirli bir sÃ¼re kayÄ±t yapmak iÃ§in:
    ```bash
    python3 main.py --live --duration 60 # 60 saniye kayÄ±t yapar
    ```

2.  **Dosyadan Ses Ä°ÅŸleme:** Mevcut bir `.wav` dosyasÄ±nÄ± iÅŸler.
    ```bash
    python3 main.py --input-file /path/to/your/audio.wav
    ```

### ğŸ“‚ Proje YapÄ±sÄ±
```
.
â”œâ”€â”€ capture.py        # Ses yakalama ve ADC kontrol modÃ¼lÃ¼
â”œâ”€â”€ onisleme.py       # Ses Ã¶niÅŸleme (gÃ¼rÃ¼ltÃ¼ azaltma, VAD) modÃ¼lÃ¼
â”œâ”€â”€ analiz.py         # KonuÅŸmacÄ± tespiti (diarization) modÃ¼lÃ¼
â”œâ”€â”€ output.py         # SonuÃ§larÄ± gÃ¶rselleÅŸtirme ve raporlama modÃ¼lÃ¼
â”œâ”€â”€ main.py           # Ana betik, tÃ¼m modÃ¼lleri yÃ¶netir
â”œâ”€â”€ config.py         # YapÄ±landÄ±rma ayarlarÄ± (API token, ses parametreleri)
â”œâ”€â”€ requirements.txt  # Gerekli Python kÃ¼tÃ¼phaneleri
â””â”€â”€ README.md         # Bu dosya
```

### ğŸ™ TeÅŸekkÃ¼r

Bu proje, **TÃœBÄ°TAK Bilim Ä°nsanÄ± Destek ProgramlarÄ± BaÅŸkanlÄ±ÄŸÄ± (BÄ°DEB)** tarafÄ±ndan yÃ¼rÃ¼tÃ¼len **2209-A Ãœniversite Ã–ÄŸrencileri AraÅŸtÄ±rma Projeleri DesteÄŸi ProgramÄ±** kapsamÄ±nda desteklenmiÅŸtir.

### ğŸ“„ Lisans

Bu proje MIT LisansÄ± ile lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in `LICENSE` dosyasÄ±na bakÄ±nÄ±z.

---
---

## <a name="english-version"></a>English Version
*(Note: This text was created with artificial intelligence.)*

### ğŸ¯ Project Goal

The primary goal of this project is to detect the number of speakers in an environment through audio analysis. This information can be used in various automation scenarios, such as controlling lighting, heating, and air conditioning systems in smart buildings to save energy. The system is designed as an effective, privacy-first alternative to camera-based systems.

### ğŸ–¼ï¸ Visuals

**Circuit Diagram:**
[![Image](https://i.hizliresim.com/dciq0h9.png)](https://hizliresim.com/dciq0h9)

### ğŸ› ï¸ Technology Stack

#### Hardware
* **Processor:** Raspberry Pi 5 (8GB)
* **Microphone:** MAX9814 Microphone Amplifier (with Automatic Gain Control)
* **ADC:** MCP3204 12-bit Analog-to-Digital Converter
* **Display:** Raspberry Pi 5" Touchscreen Display (for development and output visualization)
* **Other:** Official Raspberry Pi 27W Power Supply, Breadboard, Jumper Wires

#### Software
* **Language:** Python 3
* **Core Libraries:**
  * `pyannote.audio`: For speaker diarization. The `pyannote/speaker-diarization-3.1` model was used.
  * `spidev`: For SPI communication between Raspberry Pi and MCP3204 ADC.
  * `librosa` & `soundfile`: For reading and processing audio files.
  * `noisereduce`: For noise reduction.
  * `webrtcvad`: For Voice Activity Detection (VAD).
  * `numpy`: For numerical operations.
  * `matplotlib`: For generating output graphs.

### âš™ï¸ System Architecture

The system has a workflow consisting of 4 main modules:
1.  **Audio Capture (`capture.py`):** Captures and digitizes the analog audio signal via MAX9814 and MCP3204.
2.  **Audio Preprocessing (`onisleme.py`):** Reduces noise, normalizes the signal, and removes silent parts from the captured audio.
3.  **Analysis (`analiz.py`):** Detects and labels speakers in the cleaned audio segment using the `pyannote.audio` model.
4.  **Output (`output.py`):** Displays the analysis results in the terminal and generates a speaker timeline graph.

### ğŸš€ Installation

1.  **Hardware Setup:** Assemble the components on a breadboard according to the circuit diagram above.
2.  **Raspberry Pi Configuration:**
    * Install Raspberry Pi OS (64-bit).
    * Open the terminal and run `sudo raspi-config`.
    * Navigate to `Interface Options` -> `SPI` and enable the SPI interface.
3.  **Software Dependencies:**
    * Clone the project files: `git clone [Add your project's GitHub link here]`
    * Navigate to the project directory: `cd [project-folder-name]`
    * Install the required Python libraries:
      ```bash
      pip install -r requirements.txt
      ```

### ğŸ”§ Configuration

This project requires a Hugging Face user token to work.

1.  Create a token with `READ` permissions from the [Hugging Face](https://huggingface.co/settings/tokens) website.
2.  Assign the created token to the `HUGGINGFACE_TOKEN` variable in the `config.py` file:
    ```python
    # config.py
    HUGGINGFACE_TOKEN = "hf_YourHuggingFaceTokenGoesHere"
    ```

### âš¡ Usage

The project is run via the `main.py` script. It has two main modes:

1.  **Live Audio Processing:** Records and processes audio from the microphone in real-time.
    ```bash
    python3 main.py --live
    ```
    * To record for a specific duration:
    ```bash
    python3 main.py --live --duration 60 # Records for 60 seconds
    ```

2.  **File-based Audio Processing:** Processes an existing `.wav` file.
    ```bash
    python3 main.py --input-file /path/to/your/audio.wav
    ```

### ğŸ“‚ Project Structure
```
.
â”œâ”€â”€ capture.py        # Audio capture and ADC control module
â”œâ”€â”€ onisleme.py       # Audio preprocessing (noise reduction, VAD) module
â”œâ”€â”€ analiz.py         # Speaker diarization module
â”œâ”€â”€ output.py         # Results visualization and reporting module
â”œâ”€â”€ main.py           # Main script, manages all modules
â”œâ”€â”€ config.py         # Configuration settings (API token, audio parameters)
â”œâ”€â”€ requirements.txt  # Required Python libraries
â””â”€â”€ README.md         # This file
```

### ğŸ™ Acknowledgments

This project has been supported by the **TÃœBÄ°TAK Scientist Support Programs Directorate (BÄ°DEB)** under the **2209-A University Students Research Projects Support Program**.

### ğŸ“„ License

This project is licensed under the MIT License. See the `LICENSE` file for details.
